{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Optimization & ROI Analysis\n",
    "\n",
    "**Purpose:** Optimize the classification threshold to maximize business value (ROI) rather than statistical metrics.\n",
    "\n",
    "**Context:** The default threshold (0.5) may not be optimal for business objectives. We want to find the threshold that maximizes net savings from retention campaigns.\n",
    "\n",
    "**Author:** Noah Gallagher  \n",
    "**Date:** November 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_recall_curve, roc_curve, \n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Project imports\n",
    "from src import config\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = joblib.load(config.MODEL_FILE)\n",
    "print(f\"Loaded model: {type(model).__name__}\")\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv(config.TEST_DATA_FILE)\n",
    "X_test = test_data.drop(config.TARGET_COLUMN, axis=1)\n",
    "y_test = test_data[config.TARGET_COLUMN]\n",
    "\n",
    "print(f\"Test set size: {len(X_test)} customers\")\n",
    "print(f\"Churn rate: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Default predictions (threshold = 0.5)\n",
    "y_pred_default = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"Prediction distribution:\")\n",
    "print(pd.Series(y_pred_proba).describe())\n",
    "\n",
    "# Visualize probability distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(y_pred_proba[y_test == 0], bins=50, alpha=0.5, label='No Churn (Actual)', color='green')\n",
    "plt.hist(y_pred_proba[y_test == 1], bins=50, alpha=0.5, label='Churn (Actual)', color='red')\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', label='Default Threshold')\n",
    "plt.xlabel('Predicted Churn Probability')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.title('Distribution of Predicted Probabilities by Actual Churn Status')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Business Cost Parameters\n",
    "\n",
    "Define the economic framework for evaluating model performance:\n",
    "\n",
    "- **Customer Lifetime Value (CLV):** Average revenue from a retained customer\n",
    "- **Retention Cost:** Cost of intervention (outreach + discount)\n",
    "- **Churn Cost:** Lost revenue when a customer leaves\n",
    "\n",
    "**Cost-Benefit Matrix:**\n",
    "\n",
    "| Actual \\ Predicted | Predict No Churn | Predict Churn |\n",
    "|--------------------|------------------|---------------|\n",
    "| **No Churn** | $0 (True Negative) | -$100 (False Positive - wasted intervention) |\n",
    "| **Churn** | -$1,500 (False Negative - missed churner) | +$1,400 (True Positive - saved customer, net of intervention cost) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business parameters from config\n",
    "CLV = config.CUSTOMER_LIFETIME_VALUE  # $2,000\n",
    "RETENTION_COST = config.RETENTION_COST  # $100\n",
    "CHURN_COST = config.CHURN_COST  # $1,500\n",
    "\n",
    "# Retention success rate (% of targeted churners who actually stay)\n",
    "RETENTION_SUCCESS_RATE = 0.70\n",
    "\n",
    "print(f\"Customer Lifetime Value: ${CLV:,.0f}\")\n",
    "print(f\"Retention Intervention Cost: ${RETENTION_COST:,.0f}\")\n",
    "print(f\"Cost of Lost Customer: ${CHURN_COST:,.0f}\")\n",
    "print(f\"Retention Success Rate: {RETENTION_SUCCESS_RATE:.0%}\")\n",
    "print(f\"\\nValue of saving one churner: ${CHURN_COST - RETENTION_COST:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ROI Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_business_metrics(y_true, y_pred, retention_success_rate=0.70):\n",
    "    \"\"\"\n",
    "    Calculate business impact metrics based on confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Actual churn labels (0 = no churn, 1 = churn)\n",
    "        y_pred: Predicted churn labels (0 = no churn, 1 = churn)\n",
    "        retention_success_rate: % of targeted churners who are successfully retained\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with business metrics\n",
    "    \"\"\"\n",
    "    # Confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    # Statistical metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Business calculations\n",
    "    # True Positives: Correctly identified churners\n",
    "    # With intervention, retention_success_rate% are saved\n",
    "    customers_saved = tp * retention_success_rate\n",
    "    revenue_saved = customers_saved * CHURN_COST\n",
    "    \n",
    "    # False Positives: Incorrectly flagged non-churners (wasted intervention cost)\n",
    "    wasted_cost = fp * RETENTION_COST\n",
    "    \n",
    "    # False Negatives: Missed churners (lost revenue)\n",
    "    lost_revenue = fn * CHURN_COST\n",
    "    \n",
    "    # True Negatives: Correctly identified non-churners (no cost, no benefit)\n",
    "    # No action taken, no cost\n",
    "    \n",
    "    # Total intervention cost\n",
    "    total_intervention_cost = (tp + fp) * RETENTION_COST\n",
    "    \n",
    "    # Net savings\n",
    "    net_savings = revenue_saved - total_intervention_cost - lost_revenue\n",
    "    \n",
    "    # ROI\n",
    "    roi = (revenue_saved - total_intervention_cost) / total_intervention_cost if total_intervention_cost > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        # Confusion matrix\n",
    "        'true_negatives': tn,\n",
    "        'false_positives': fp,\n",
    "        'false_negatives': fn,\n",
    "        'true_positives': tp,\n",
    "        \n",
    "        # Statistical metrics\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        \n",
    "        # Business metrics\n",
    "        'customers_targeted': tp + fp,\n",
    "        'customers_saved': customers_saved,\n",
    "        'revenue_saved': revenue_saved,\n",
    "        'wasted_cost': wasted_cost,\n",
    "        'lost_revenue': lost_revenue,\n",
    "        'total_intervention_cost': total_intervention_cost,\n",
    "        'net_savings': net_savings,\n",
    "        'roi': roi\n",
    "    }\n",
    "\n",
    "# Test with default threshold\n",
    "default_metrics = calculate_business_metrics(y_test, y_pred_default, RETENTION_SUCCESS_RATE)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DEFAULT THRESHOLD (0.5) PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  True Negatives:  {default_metrics['true_negatives']:>4}  (Correctly identified non-churners)\")\n",
    "print(f\"  False Positives: {default_metrics['false_positives']:>4}  (Wasted interventions)\")\n",
    "print(f\"  False Negatives: {default_metrics['false_negatives']:>4}  (Missed churners)\")\n",
    "print(f\"  True Positives:  {default_metrics['true_positives']:>4}  (Correctly identified churners)\")\n",
    "print(f\"\\nStatistical Metrics:\")\n",
    "print(f\"  Accuracy:  {default_metrics['accuracy']:.1%}\")\n",
    "print(f\"  Precision: {default_metrics['precision']:.1%}\")\n",
    "print(f\"  Recall:    {default_metrics['recall']:.1%}\")\n",
    "print(f\"  F1 Score:  {default_metrics['f1_score']:.1%}\")\n",
    "print(f\"\\nBusiness Impact:\")\n",
    "print(f\"  Customers Targeted:     {default_metrics['customers_targeted']:>4}\")\n",
    "print(f\"  Customers Saved:        {default_metrics['customers_saved']:>6.0f}\")\n",
    "print(f\"  Revenue Saved:          ${default_metrics['revenue_saved']:>9,.0f}\")\n",
    "print(f\"  Intervention Cost:      ${default_metrics['total_intervention_cost']:>9,.0f}\")\n",
    "print(f\"  Lost Revenue (FN):      ${default_metrics['lost_revenue']:>9,.0f}\")\n",
    "print(f\"  Net Savings:            ${default_metrics['net_savings']:>9,.0f}\")\n",
    "print(f\"  ROI:                    {default_metrics['roi']:>9.1%}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Threshold Optimization\n",
    "\n",
    "Test a range of thresholds (0.01 to 0.99) to find the one that maximizes net savings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test range of thresholds\n",
    "thresholds = np.arange(0.05, 1.00, 0.01)\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Make predictions with this threshold\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_business_metrics(y_test, y_pred, RETENTION_SUCCESS_RATE)\n",
    "    metrics['threshold'] = threshold\n",
    "    results.append(metrics)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find optimal threshold\n",
    "optimal_idx = results_df['net_savings'].idxmax()\n",
    "optimal_threshold = results_df.loc[optimal_idx, 'threshold']\n",
    "optimal_net_savings = results_df.loc[optimal_idx, 'net_savings']\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.2f}\")\n",
    "print(f\"Maximum Net Savings: ${optimal_net_savings:,.0f}\")\n",
    "print(f\"\\nImprovement over default (0.5):\")\n",
    "print(f\"  Default Net Savings: ${default_metrics['net_savings']:,.0f}\")\n",
    "print(f\"  Optimal Net Savings: ${optimal_net_savings:,.0f}\")\n",
    "print(f\"  Additional Savings:  ${optimal_net_savings - default_metrics['net_savings']:,.0f}\")\n",
    "\n",
    "# Display top 10 thresholds\n",
    "print(\"\\nTop 10 Thresholds by Net Savings:\")\n",
    "print(results_df.nlargest(10, 'net_savings')[[\n",
    "    'threshold', 'recall', 'precision', 'customers_targeted', \n",
    "    'customers_saved', 'net_savings', 'roi'\n",
    "]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Threshold Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Net Savings vs Threshold\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(results_df['threshold'], results_df['net_savings'] / 1000, linewidth=2, color='#2ca02c')\n",
    "ax1.axvline(x=optimal_threshold, color='red', linestyle='--', label=f'Optimal: {optimal_threshold:.2f}')\n",
    "ax1.axvline(x=0.5, color='gray', linestyle=':', label='Default: 0.50')\n",
    "ax1.set_xlabel('Classification Threshold', fontsize=12)\n",
    "ax1.set_ylabel('Net Savings ($000s)', fontsize=12)\n",
    "ax1.set_title('Net Savings vs. Classification Threshold', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Precision & Recall vs Threshold\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(results_df['threshold'], results_df['precision'], linewidth=2, label='Precision', color='#1f77b4')\n",
    "ax2.plot(results_df['threshold'], results_df['recall'], linewidth=2, label='Recall', color='#ff7f0e')\n",
    "ax2.axvline(x=optimal_threshold, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.axvline(x=0.5, color='gray', linestyle=':', alpha=0.5)\n",
    "ax2.set_xlabel('Classification Threshold', fontsize=12)\n",
    "ax2.set_ylabel('Score', fontsize=12)\n",
    "ax2.set_title('Precision & Recall vs. Threshold', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: ROI vs Threshold\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(results_df['threshold'], results_df['roi'] * 100, linewidth=2, color='#9467bd')\n",
    "ax3.axvline(x=optimal_threshold, color='red', linestyle='--', label=f'Optimal: {optimal_threshold:.2f}')\n",
    "ax3.axvline(x=0.5, color='gray', linestyle=':', label='Default: 0.50')\n",
    "ax3.set_xlabel('Classification Threshold', fontsize=12)\n",
    "ax3.set_ylabel('ROI (%)', fontsize=12)\n",
    "ax3.set_title('Return on Investment vs. Threshold', fontsize=14, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Customers Targeted vs Customers Saved\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(results_df['threshold'], results_df['customers_targeted'], linewidth=2, label='Customers Targeted', color='#d62728')\n",
    "ax4.plot(results_df['threshold'], results_df['customers_saved'], linewidth=2, label='Customers Saved', color='#2ca02c')\n",
    "ax4.axvline(x=optimal_threshold, color='red', linestyle='--', alpha=0.5)\n",
    "ax4.axvline(x=0.5, color='gray', linestyle=':', alpha=0.5)\n",
    "ax4.set_xlabel('Classification Threshold', fontsize=12)\n",
    "ax4.set_ylabel('Number of Customers', fontsize=12)\n",
    "ax4.set_title('Customer Volume vs. Threshold', fontsize=14, fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/threshold_optimization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved to outputs/figures/threshold_optimization.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optimal Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with optimal threshold\n",
    "y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "optimal_metrics = calculate_business_metrics(y_test, y_pred_optimal, RETENTION_SUCCESS_RATE)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"OPTIMAL THRESHOLD ({optimal_threshold:.2f}) PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  True Negatives:  {optimal_metrics['true_negatives']:>4}  (Correctly identified non-churners)\")\n",
    "print(f\"  False Positives: {optimal_metrics['false_positives']:>4}  (Wasted interventions)\")\n",
    "print(f\"  False Negatives: {optimal_metrics['false_negatives']:>4}  (Missed churners)\")\n",
    "print(f\"  True Positives:  {optimal_metrics['true_positives']:>4}  (Correctly identified churners)\")\n",
    "print(f\"\\nStatistical Metrics:\")\n",
    "print(f\"  Accuracy:  {optimal_metrics['accuracy']:.1%}\")\n",
    "print(f\"  Precision: {optimal_metrics['precision']:.1%}\")\n",
    "print(f\"  Recall:    {optimal_metrics['recall']:.1%}\")\n",
    "print(f\"  F1 Score:  {optimal_metrics['f1_score']:.1%}\")\n",
    "print(f\"\\nBusiness Impact:\")\n",
    "print(f\"  Customers Targeted:     {optimal_metrics['customers_targeted']:>4}\")\n",
    "print(f\"  Customers Saved:        {optimal_metrics['customers_saved']:>6.0f}\")\n",
    "print(f\"  Revenue Saved:          ${optimal_metrics['revenue_saved']:>9,.0f}\")\n",
    "print(f\"  Intervention Cost:      ${optimal_metrics['total_intervention_cost']:>9,.0f}\")\n",
    "print(f\"  Lost Revenue (FN):      ${optimal_metrics['lost_revenue']:>9,.0f}\")\n",
    "print(f\"  Net Savings:            ${optimal_metrics['net_savings']:>9,.0f}\")\n",
    "print(f\"  ROI:                    {optimal_metrics['roi']:>9.1%}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Threshold', 'Accuracy', 'Precision', 'Recall', 'F1 Score',\n",
    "               'Customers Targeted', 'Customers Saved', 'Net Savings', 'ROI'],\n",
    "    'Default (0.5)': [\n",
    "        0.50,\n",
    "        default_metrics['accuracy'],\n",
    "        default_metrics['precision'],\n",
    "        default_metrics['recall'],\n",
    "        default_metrics['f1_score'],\n",
    "        default_metrics['customers_targeted'],\n",
    "        default_metrics['customers_saved'],\n",
    "        default_metrics['net_savings'],\n",
    "        default_metrics['roi']\n",
    "    ],\n",
    "    f'Optimal ({optimal_threshold:.2f})': [\n",
    "        optimal_threshold,\n",
    "        optimal_metrics['accuracy'],\n",
    "        optimal_metrics['precision'],\n",
    "        optimal_metrics['recall'],\n",
    "        optimal_metrics['f1_score'],\n",
    "        optimal_metrics['customers_targeted'],\n",
    "        optimal_metrics['customers_saved'],\n",
    "        optimal_metrics['net_savings'],\n",
    "        optimal_metrics['roi']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\\nCOMPARISON: DEFAULT VS. OPTIMAL THRESHOLD\")\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sensitivity Analysis\n",
    "\n",
    "Test how robust the optimal threshold is to changes in business parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different retention success rates\n",
    "retention_rates = [0.50, 0.60, 0.70, 0.80, 0.90]\n",
    "sensitivity_results = []\n",
    "\n",
    "for rate in retention_rates:\n",
    "    # Find optimal threshold for this retention rate\n",
    "    temp_results = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        metrics = calculate_business_metrics(y_test, y_pred, rate)\n",
    "        metrics['threshold'] = threshold\n",
    "        temp_results.append(metrics)\n",
    "    \n",
    "    temp_df = pd.DataFrame(temp_results)\n",
    "    optimal_idx = temp_df['net_savings'].idxmax()\n",
    "    \n",
    "    sensitivity_results.append({\n",
    "        'retention_rate': rate,\n",
    "        'optimal_threshold': temp_df.loc[optimal_idx, 'threshold'],\n",
    "        'net_savings': temp_df.loc[optimal_idx, 'net_savings'],\n",
    "        'roi': temp_df.loc[optimal_idx, 'roi']\n",
    "    })\n",
    "\n",
    "sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "\n",
    "print(\"SENSITIVITY ANALYSIS: Retention Success Rate Impact\")\n",
    "print(sensitivity_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Optimal threshold vs retention rate\n",
    "axes[0].plot(sensitivity_df['retention_rate'] * 100, sensitivity_df['optimal_threshold'], \n",
    "             marker='o', linewidth=2, markersize=8, color='#1f77b4')\n",
    "axes[0].set_xlabel('Retention Success Rate (%)', fontsize=12)\n",
    "axes[0].set_ylabel('Optimal Classification Threshold', fontsize=12)\n",
    "axes[0].set_title('Optimal Threshold vs. Retention Success Rate', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Net savings vs retention rate\n",
    "axes[1].plot(sensitivity_df['retention_rate'] * 100, sensitivity_df['net_savings'] / 1000, \n",
    "             marker='o', linewidth=2, markersize=8, color='#2ca02c')\n",
    "axes[1].set_xlabel('Retention Success Rate (%)', fontsize=12)\n",
    "axes[1].set_ylabel('Net Savings ($000s)', fontsize=12)\n",
    "axes[1].set_title('Net Savings vs. Retention Success Rate', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/sensitivity_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization saved to outputs/figures/sensitivity_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Recommendations\n",
    "\n",
    "Based on this analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"THRESHOLD OPTIMIZATION RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n1. RECOMMENDED THRESHOLD: {optimal_threshold:.2f}\")\n",
    "print(f\"   - This threshold maximizes net savings at ${optimal_net_savings:,.0f}\")\n",
    "print(f\"   - Represents ${optimal_net_savings - default_metrics['net_savings']:,.0f} improvement over default (0.5)\")\n",
    "\n",
    "print(f\"\\n2. BUSINESS JUSTIFICATION:\")\n",
    "print(f\"   - Recall: {optimal_metrics['recall']:.1%} (catches {optimal_metrics['recall']:.0%} of churners)\")\n",
    "print(f\"   - Precision: {optimal_metrics['precision']:.1%} ({optimal_metrics['precision']:.0%} of targeted customers are actual churners)\")\n",
    "print(f\"   - ROI: {optimal_metrics['roi']:.0%} (every $1 spent returns ${optimal_metrics['roi'] + 1:.2f})\")\n",
    "\n",
    "print(f\"\\n3. TRADE-OFFS:\")\n",
    "if optimal_threshold < 0.5:\n",
    "    print(f\"   - Lower threshold means MORE customers targeted ({optimal_metrics['customers_targeted']} vs {default_metrics['customers_targeted']})\")\n",
    "    print(f\"   - Higher recall ({optimal_metrics['recall']:.1%}) but lower precision ({optimal_metrics['precision']:.1%})\")\n",
    "    print(f\"   - Justified by high cost of missing churners (${CHURN_COST} vs ${RETENTION_COST} intervention)\")\n",
    "else:\n",
    "    print(f\"   - Higher threshold means FEWER customers targeted ({optimal_metrics['customers_targeted']} vs {default_metrics['customers_targeted']})\")\n",
    "    print(f\"   - Lower recall ({optimal_metrics['recall']:.1%}) but higher precision ({optimal_metrics['precision']:.1%})\")\n",
    "    print(f\"   - Focused on high-confidence predictions to minimize wasted interventions\")\n",
    "\n",
    "print(f\"\\n4. SENSITIVITY:\")\n",
    "print(f\"   - Optimal threshold ranges from {sensitivity_df['optimal_threshold'].min():.2f} to {sensitivity_df['optimal_threshold'].max():.2f}\")\n",
    "print(f\"     across retention success rates of {sensitivity_df['retention_rate'].min():.0%}-{sensitivity_df['retention_rate'].max():.0%}\")\n",
    "print(f\"   - Recommendation is robust to realistic variation in retention effectiveness\")\n",
    "\n",
    "print(f\"\\n5. IMPLEMENTATION:\")\n",
    "print(f\"   - Update dashboard to use threshold = {optimal_threshold:.2f}\")\n",
    "print(f\"   - Monitor actual retention success rate and re-optimize quarterly\")\n",
    "print(f\"   - Consider A/B testing: {optimal_threshold:.2f} vs. 0.50 to validate in production\")\n",
    "\n",
    "print(f\"\\n6. EXPECTED ANNUAL IMPACT (scaling to full customer base):\")\n",
    "test_size_ratio = len(X_test) / 7043  # test is 20% of full dataset\n",
    "annual_net_savings = optimal_net_savings / test_size_ratio\n",
    "print(f\"   - Test set net savings: ${optimal_net_savings:,.0f}\")\n",
    "print(f\"   - Projected annual savings (full customer base): ${annual_net_savings:,.0f}\")\n",
    "print(f\"   - Additional savings vs default threshold: ${(optimal_net_savings - default_metrics['net_savings']) / test_size_ratio:,.0f}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save threshold optimization results\n",
    "results_df.to_csv('../outputs/reports/threshold_optimization_results.csv', index=False)\n",
    "print(\"Saved: outputs/reports/threshold_optimization_results.csv\")\n",
    "\n",
    "# Save sensitivity analysis\n",
    "sensitivity_df.to_csv('../outputs/reports/sensitivity_analysis_results.csv', index=False)\n",
    "print(\"Saved: outputs/reports/sensitivity_analysis_results.csv\")\n",
    "\n",
    "# Save optimal threshold configuration\n",
    "optimal_config = {\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'default_threshold': 0.5,\n",
    "    'retention_success_rate': RETENTION_SUCCESS_RATE,\n",
    "    'business_parameters': {\n",
    "        'CLV': CLV,\n",
    "        'retention_cost': RETENTION_COST,\n",
    "        'churn_cost': CHURN_COST\n",
    "    },\n",
    "    'optimal_metrics': optimal_metrics,\n",
    "    'default_metrics': default_metrics\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../outputs/reports/optimal_threshold_config.json', 'w') as f:\n",
    "    # Convert numpy types to Python types for JSON serialization\n",
    "    def convert_types(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: convert_types(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (np.int64, np.int32)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float64, np.float32)):\n",
    "            return float(obj)\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    json.dump(convert_types(optimal_config), f, indent=2)\n",
    "\n",
    "print(\"Saved: outputs/reports/optimal_threshold_config.json\")\n",
    "print(\"\\nAll results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Business-Driven Optimization**: Optimized classification threshold based on business costs (CLV, retention cost, churn cost) rather than statistical metrics alone.\n",
    "\n",
    "2. **ROI Maximization**: Found the threshold that maximizes net savings and ROI, accounting for intervention costs and retention success rates.\n",
    "\n",
    "3. **Sensitivity Analysis**: Validated that the optimal threshold is robust to realistic variation in business parameters.\n",
    "\n",
    "4. **Actionable Recommendations**: Provided clear implementation guidance with expected business impact.\n",
    "\n",
    "**Key Takeaway:** The default threshold of 0.5 is rarely optimal for business applications. By incorporating domain knowledge about costs and benefits, we can significantly improve the value delivered by the model.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "- Implement optimal threshold in production dashboard\n",
    "- Run A/B test to validate in real-world conditions (see [A_B_TEST_PLAN.md](../A_B_TEST_PLAN.md))\n",
    "- Monitor actual retention success rate and re-optimize quarterly\n",
    "- Consider cost-sensitive learning algorithms that incorporate business costs during training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
